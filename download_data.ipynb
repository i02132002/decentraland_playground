{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import requests\n",
    "import json\n",
    "from gql import gql, Client\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from sys import argv\n",
    "\n",
    "from gql.transport.requests import RequestsHTTPTransport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Query string used to get latest parcel transaction information\n",
    "mystring = \"\"\"\n",
    "{{\n",
    "  orders (first: 1000 orderBy: updatedAt, orderDirection: asc where: {{ status:sold category:parcel updatedAt_gt:\"{0}\"}}, subgraphError: allow) {{\n",
    " \n",
    " \n",
    "    category\n",
    "    status\n",
    "    price\n",
    "    id\n",
    "    updatedAt\n",
    "    nft {{\n",
    "      owner {{\n",
    "        id\n",
    "      }}\n",
    "      name\n",
    "      estate {{\n",
    "        id\n",
    "      }}\n",
    "      parcel {{\n",
    "        id\n",
    "        x\n",
    "        y\n",
    "      }}\n",
    "     \n",
    "      owner {{\n",
    "        id\n",
    "      }}\n",
    "    }}\n",
    "   \n",
    "  }}\n",
    " \n",
    "}}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "#update parameter used in mystring to start querying the database at the earliest update date of sale. The update \n",
    "#date is specified in epoch date and needs to be converted to datetime for human consumption.\n",
    "update = 1\n",
    "\n",
    "while True:\n",
    "    \n",
    "    #query the data using GraphQL python library.\n",
    "    query = gql(mystring.format(update))\n",
    "    result = client.execute(query)\n",
    "    \n",
    "    #if there is no data returned it means you reached the end and should stop querying.\n",
    "    if len(client.execute(query)['orders']) <= 1:\n",
    "        break\n",
    "   \n",
    "    else:\n",
    "        #Create a temporary dataframe to later append to the final dataframe that compiles all 1000-row dataframes.\n",
    "        df1 = pd.DataFrame()\n",
    "        df1 = pd.DataFrame(result['orders'])\n",
    "        #unfold a subdict into a series of columns.\n",
    "        df1 = df1.join(df1['nft'].apply(pd.Series),lsuffix='_1',rsuffix='_2')     \n",
    "        \n",
    "        #append your temp dataframe to your master dataset.\n",
    "        df = df.append(df1)\n",
    "        \n",
    "        #Pass into the API the max date from your dataset to fetch the next 1000 records.\n",
    "        update = df['updatedAt'].max()\n",
    "        print(\"last updated at: {}\".format(time.strftime('%Y-%m-%d', time.localtime(int(update)))))\n",
    "\n",
    "#reformat the update date in human-readable datetime format.\n",
    "df['updatedAt_dt'] = df['updatedAt'].apply(lambda x: time.strftime('%Y-%m-%d', time.localtime(int(x))) )\n",
    "df['price'] = df['price'].astype(float)/1e18\n",
    "df['owner'] = df.owner.apply(lambda x: x['id'])\n",
    "df['x'] = df.parcel.apply(lambda a: a['x'])\n",
    "df['y'] = df.parcel.apply(lambda a: a['y'])\n",
    "df['parcel_id'] = df.parcel.apply(lambda a: a['id'])\n",
    "df.to_csv('parcel_transactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String used to query parcel info\n",
    "mystring = \"\"\"\n",
    "{{\n",
    "  parcels (first: 301 orderBy: x where: {{ y_lte:\"{0}\" y_gte:\"{0}\"}} , subgraphError: allow) {{\n",
    "    id\n",
    "    tokenId\n",
    "    owner{{\n",
    "     id\n",
    "    }}\n",
    "    x\n",
    "    y\n",
    "    estate{{\n",
    "     id\n",
    "    }}\n",
    "  }}\n",
    " \n",
    "}}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "#update parameter used in mystring to start querying the database at the earliest update date of sale. The update \n",
    "#date is specified in epoch date and needs to be converted to datetime for human consumption.\n",
    "counter = 1\n",
    "\n",
    "for row_num in range(-150,151):\n",
    "    \n",
    "    #query the data using GraphQL python library.\n",
    "    query = gql(mystring.format(row_num))\n",
    "    result = client.execute(query)\n",
    "    \n",
    "    #if there is no data returned it means you reached the end and should stop querying.\n",
    "    if len(client.execute(query)['parcels']) < 1:\n",
    "        break\n",
    "   \n",
    "    else:\n",
    "        #Create a temporary dataframe to later append to the final dataframe that compiles all 1000-row dataframes.\n",
    "        df1 = pd.DataFrame()\n",
    "        df1 = pd.DataFrame(result['parcels'])\n",
    "        \n",
    "        \"\"\"\n",
    "        #unfold a subdict into a series of columns.\n",
    "        df1 = df1.join(df1['nft'].apply(pd.Series),lsuffix='_1',rsuffix='_2')     \n",
    "        \"\"\"\n",
    "        #append your temp dataframe to your master dataset.\n",
    "        df = df.append(df1)\n",
    "        \n",
    "        #Pass into the API the max date from your dataset to fetch the next 1000 records.\n",
    "        print('first {} rows done!'.format(row_num + 151))\n",
    "df['owner'] = df.owner.apply(lambda x: x['id'])\n",
    "df['x'] = df.x.apply(lambda a: int(a))\n",
    "df['y'] = df.y.apply(lambda a: int(a))\n",
    "df.to_csv('decentraland_ownership.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String used to query estate info\n",
    "mystring = \"\"\"{{\n",
    "  orders (first: 1000 orderBy: updatedAt, orderDirection: asc where: {{ status:sold category:estate updatedAt_gt:\"{0}\"}}, subgraphError: allow) {{\n",
    "    category\n",
    "    price\n",
    "    id\n",
    "    buyer\n",
    "    updatedAt\n",
    "    nft{{\n",
    "      estate{{\n",
    "        id\n",
    "        parcels{{\n",
    "        id\n",
    "        x\n",
    "        y\n",
    "        }}\n",
    "      }}\n",
    "    }}\n",
    "  }}\n",
    "}}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "#update parameter used in mystring to start querying the database at the earliest update date of sale. The update \n",
    "#date is specified in epoch date and needs to be converted to datetime for human consumption.\n",
    "update = 1\n",
    "\n",
    "while True:\n",
    "    \n",
    "    #query the data using GraphQL python library.\n",
    "    query = gql(mystring.format(update))\n",
    "    result = client.execute(query)\n",
    "    \n",
    "    #if there is no data returned it means you reached the end and should stop querying.\n",
    "    if len(client.execute(query)['orders']) <= 1:\n",
    "        break\n",
    "   \n",
    "    else:\n",
    "        #Create a temporary dataframe to later append to the final dataframe that compiles all 1000-row dataframes.\n",
    "        df1 = pd.DataFrame()\n",
    "        df1 = pd.DataFrame(result['orders'])\n",
    "        #unfold a subdict into a series of columns.\n",
    "        #df1 = df1.join(df1['nft'].apply(pd.Series),lsuffix='_1',rsuffix='_2')     \n",
    "        \n",
    "        #append your temp dataframe to your master dataset.\n",
    "        df = df.append(df1)\n",
    "        \n",
    "        #Pass into the API the max date from your dataset to fetch the next 1000 records.\n",
    "        update = df['updatedAt'].max()\n",
    "        print(\"last updated at: {}\".format(time.strftime('%Y-%m-%d', time.localtime(int(update)))))\n",
    "\n",
    "#reformat the update date in human-readable datetime format.\n",
    "df['updatedAt_dt'] = df['updatedAt'].apply(lambda x: time.strftime('%Y-%m-%d', time.localtime(int(x))) )\n",
    "df['price'] = df['price'].astype(float)/1e18\n",
    "df['parcels'] = df.nft.apply(lambda x: x['estate']).apply(lambda x: x['parcels']).apply(lambda x: [(int(i['x']),int(i['y'])) for i in x])\n",
    "df['estate_id'] = df.nft.apply(lambda x: x['estate']).apply(lambda x: x['id'])\n",
    "df.to_csv('estate_transactions.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
